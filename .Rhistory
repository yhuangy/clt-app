import pandas as pd
import matplotlib.pyplot as plt
import requests
# URL for the data set
base_url = "https://data.gov.sg/api/action/datastore_search"
url = base_url + "?resource_id=d_11e68bba3b3c76733475a72d09759eeb"
# Initial query for the data
response = requests.get(url)
results = response.json()
# Current number of rows
df = pd.DataFrame(results["result"]["records"])
df.head(6)
df.dtypes
?read.csv
Advertising <- read.csv("Data/Advertising.csv",
header = TRUE, row.names = NULL)
Advertising
View(Advertising)
summary(ADvertising)
summary(Advertising)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
fig.asp = 0.618, fig.align = 'center',  out.width = "60%")
knitr::knit_hooks$set(mysize = function(before, options, envir) {
if (before)
return(options$size)
})
rmarkdown::find_pandoc(version = "2.11.4")
library(openintro)
library(tidyverse)
library(knitr)
library(kableExtra)
library(xtable)
library(scatterplot3d)
# Read in a CSV file in the current working directory
Advertising = read.csv("Data/Advertising.csv", header = TRUE)
# Simple linear regression
lm_fit2 = lm(sales ~ TV + radio, data = Advertising)
# Display the estimation results
summary(lm_fit2)
# Display the adjusted R-squared
summary(lm_fit2)$adj.r.squared
# 95% confidence intervals
confint(lm_fit2, level = 0.95)
# Make predictions for sales
predict(lm_fit2, newdata = data.frame(TV = 150, radio = 23))
# Make predictions for sales
predict(lm_fit2, newdata = data.frame(TV = 150, radio = 10))
summary(Advertising)
7.0326 + 150*0.0475
9.3116 + 10*0.2025
12.3514 + 10*0.0547
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE,
out.width = "65%", fig.align = "center")
library(readxl)
library(tidyverse)
df = read_excel("../data/BACE_data.xls")
library(readxl)
library(tidyverse)
df = read_excel("../data/Economic_growth_data/BACE_data.xls")
View(df)
?read_excel
library(readxl)
library(tidyverse)
df = read_excel("../data/Economic_growth_data/BACE_data.xls", na = ".")
View(df)
hist(df$GR6096, breaks = 20,
main = "Distribution of GDP-per-capita growth (1960–1996)",
xlab  = "Average annual growth rate (%)")
hist(df$GR6096*100, breaks = 20,
main = "Distribution of GDP-per-capita growth (1960–1996)",
xlab  = "Average annual growth rate (%)")
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE,
out.width = "60%", fig.align = "center")
miss_df <- df %>%
summarise(across(everything(),
~ mean(is.na(.x))*100, .names = "{.col}_pctNA")) %>%
pivot_longer(everything(),
names_to = "variable", values_to = "pct_missing") %>%
arrange(desc(pct_missing))
head(miss_df, 10)
View(df)
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GDP_growth, p = 0.7, list = FALSE)
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE)
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE, na.rm = TRUE)
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE, na.rm = TRUE)
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE)
View(df)
df = df %>% filter(!is.na(GR6096))
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE)
train_df <- df[train_idx, ]
test_df <- df[-train_idx, ]
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE)
train_df <- df[train_idx, ]
test_df <- df[-train_idx, ]
# Cross validation setup
ctrl <- trainControl(method = "cv", number = 5)
# Linear regression
model_lm <- train(GR6096 ~ ., data = train_df, method = "lm", trControl = ctrl)
# Linear regression
model_lm <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "lm", trControl = ctrl)
library(readxl)
library(tidyverse)
df = read_excel("../data/Economic_growth_data/BACE_data.xls", na = ".")
hist(df$GR6096*100, breaks = 20,
main = "Distribution of GDP-per-capita growth (1960–1996)",
xlab  = "Average annual growth rate (%)")
df = df %>% filter(!is.na(GR6096)) %>%
select(-OBS)
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE)
train_df <- df[train_idx, ]
test_df <- df[-train_idx, ]
# Cross validation setup
ctrl <- trainControl(method = "cv", number = 5)
# Linear regression
model_lm <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "lm", trControl = ctrl)
df = df %>% filter(!is.na()) %>%
select(-OBS)
df = df %>% na.omit() %>% select(-OBS)
df = na.omit(df) %>% select(-OBS)
library(readxl)
library(tidyverse)
df = read_excel("../data/Economic_growth_data/BACE_data.xls", na = ".")
df = na.omit(df) %>% select(-OBS)
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE)
train_df <- df[train_idx, ]
test_df <- df[-train_idx, ]
# Cross validation setup
ctrl <- trainControl(method = "cv", number = 5)
# Linear regression
model_lm <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "lm", trControl = ctrl)
# Regression tree
model_tree <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "rpart", trControl = ctrl)
# Random forest
model_rf <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "rf", trControl = ctrl)
# KNN regression
model_knn <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "knn", trControl = ctrl, tuneLength = 10)
results <- resamples(list(
Linear = model_lm,
Tree = model_tree,
RF = model_rf,
KNN = model_knn
))
summary(results)
bwplot(results, metric = "RMSE")
results <- resamples(list(
Linear = model_lm,
Tree = model_tree,
RF = model_rf,
KNN = model_knn))
summary(results)
library(randomForest)
# Step 1: Fit a random forest model
set.seed(123)
rf_model <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df,
method = "rf",
importance = TRUE,
trControl = trainControl(method = "cv", number = 5))
# Step 2: Extract variable importance
var_imp <- varImp(rf_model, scale = TRUE)
plot(var_imp, top = 20, main = "Top 20 Important Variables")
# Step 3: Get top variables
important_vars <- rownames(var_imp$importance)[order(var_imp$importance$Overall, decreasing = TRUE)]
head(important_vars, 10)  # top 10
# Top 15 variables
top_vars <- rownames(importance_df)[order(importance_df$Overall, decreasing = TRUE)][1:15]
# Top 15 variables
importance_df <- varImp(rf_model)$importance
top_vars <- rownames(importance_df)[order(importance_df$Overall, decreasing = TRUE)][1:15]
# Top 15 variables
importance_df <- varImp(rf_model)$importance
top_vars <- rownames(importance_df)[order(importance_df$Overall, decreasing = TRUE)][1:15]
# Keep only rows with complete data in GR6096 and the top 15 important variables
df_clean = df %>% select(GR6096, all_of(top_vars)) %>% drop_na()
# Top 15 variables
importance_df <- varImp(rf_model)$importance
top_vars <- rownames(importance_df)[order(importance_df$Overall, decreasing = TRUE)][1:10]
# Keep only rows with complete data in GR6096 and the top 10 important variables
df_clean = df %>% select(GR6096, all_of(top_vars)) %>% drop_na()
View(df_clean)
# Top 15 variables
importance_df <- varImp(rf_model)$importance
top_vars <- rownames(importance_df)[order(importance_df$Overall, decreasing = TRUE)][1:5]
# Keep only rows with complete data in GR6096 and the top 10 important variables
df_clean = df %>% select(GR6096, all_of(top_vars)) %>% drop_na()
# Top 15 variables
importance_df <- varImp(rf_model)$importance
top_vars <- rownames(importance_df)[order(importance_df$Overall, decreasing = TRUE)][1:10]
# Keep only rows with complete data in GR6096 and the top 10 important variables
df = read_excel("../data/Economic_growth_data/BACE_data.xls", na = ".")
df_clean = df %>% select(GR6096, all_of(top_vars)) %>% drop_na()
library(caret)
set.seed(123)
train_idx <- createDataPartition(df$GR6096, p = 0.7, list = FALSE)
library(caret)
set.seed(123)
train_idx <- createDataPartition(df_clean$GR6096, p = 0.7, list = FALSE)
train_df <- df_clean[train_idx, ]
test_df <- df_clean[-train_idx, ]
# Cross validation setup
ctrl <- trainControl(method = "cv", number = 5)
# Linear regression
model_lm <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "lm", trControl = ctrl)
# Top 15 variables
importance_df <- varImp(rf_model)$importance
top_vars <- rownames(importance_df)[order(importance_df$Overall, decreasing = TRUE)][1:10]
# Keep only rows with complete data in GR6096 and the top 10 important variables
df = read_excel("../data/Economic_growth_data/BACE_data.xls", na = ".")
df_clean = df %>% select(GR6096, CODE, COUNTRY, all_of(top_vars)) %>% drop_na()
library(caret)
set.seed(123)
train_idx <- createDataPartition(df_clean$GR6096, p = 0.7, list = FALSE)
train_df <- df_clean[train_idx, ]
test_df <- df_clean[-train_idx, ]
# Cross validation setup
ctrl <- trainControl(method = "cv", number = 5)
# Linear regression
model_lm <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "lm", trControl = ctrl)
# Regression tree
model_tree <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "rpart", trControl = ctrl)
# Random forest
model_rf <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "rf", trControl = ctrl)
# KNN regression
model_knn <- train(GR6096 ~ . - CODE - COUNTRY, data = train_df, method = "knn", trControl = ctrl, tuneLength = 10)
results <- resamples(list(
Linear = model_lm,
Tree = model_tree,
RF = model_rf,
KNN = model_knn))
summary(results)
shiny::runApp('~/NUS Dropbox/Yuting Huang/NUS/AY2526 Sem 1/DSE1101/Shiny/CLT')
runApp('~/NUS Dropbox/Yuting Huang/NUS/AY2526 Sem 1/DSE1101/Shiny/CLT')
runApp('~/NUS Dropbox/Yuting Huang/NUS/AY2526 Sem 1/DSE1101/Shiny/CLT')
runApp('~/NUS Dropbox/Yuting Huang/NUS/AY2526 Sem 1/DSE1101/Shiny/CLT')
runApp('~/NUS Dropbox/Yuting Huang/NUS/AY2526 Sem 1/DSE1101/Shiny/CLT')
runApp('~/NUS Dropbox/Yuting Huang/NUS/AY2526 Sem 1/DSE1101/Shiny/CLT')
runApp('~/NUS Dropbox/Yuting Huang/NUS/AY2526 Sem 1/DSE1101/Shiny/CLT')
rsconnect::writeManifest()
rsconnect::writeManifest(contentCategory = "site")
rsconnect::writeManifest()
rsconnect::writeManifest(appDir = ".")
gwd()
getwd()
setwd("~/NUS Dropbox/Yuting Huang/NUS/AY2526 Sem 1/DSE1101/Shiny/CLT")
rsconnect::writeManifest()
runApp()
runApp()
n  <- 30
mu <- 0
sd <- 10
rnorm(n, mean = mu, sd = sd)
runApp()
10/(sqrt(30))
runApp()
runApp()
runApp()
runApp()
